{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import uproot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [ "This file is very messy but shows how the root files are converted into the csv files with the labels on the supercells"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TOB_ET  TOB_eta  TOB_ieta  TOB_ietabin   TOB_phi  offline_ele_pt  \\\n",
      "0  22.500000  -0.2875        -3            2  2.896156       22.860487   \n",
      "1  32.200001  -0.5875        -6            5 -1.619884       30.928337   \n",
      "2  20.000000   0.1375         1            1 -0.638136       20.700048   \n",
      "3   8.900000   1.4875        14           14  1.030835       42.459045   \n",
      "4  38.500000   0.2125         2            2 -1.914408       36.940105   \n",
      "\n",
      "   offline_ele_eta  offline_ele_eta_cal  offline_ele_phi  offline_ele_phi_cal  \\\n",
      "0        -0.278998            -0.286387         2.860483             2.882413   \n",
      "1        -0.596390            -0.588561        -1.626244            -1.639588   \n",
      "2         0.206087             0.150844        -0.584220            -0.609071   \n",
      "3         1.508192             1.500046         0.987355             0.987977   \n",
      "4         0.249134             0.218442        -1.945299            -1.933747   \n",
      "\n",
      "   ...  eFEX_L2_ET  eFEX_L3_ET  \\\n",
      "0  ...   12.175000         0.0   \n",
      "1  ...   21.424999         0.0   \n",
      "2  ...    9.450000         0.0   \n",
      "3  ...    4.450000         0.0   \n",
      "4  ...   22.174999         0.0   \n",
      "\n",
      "                                        SuperCell_ET   eFEX_ReC  eFEX_ReE  \\\n",
      "0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  12.175000       0.0   \n",
      "1  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  21.424999       0.0   \n",
      "2  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   9.450000       0.0   \n",
      "3  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   4.450000       0.0   \n",
      "4  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  22.174999       0.0   \n",
      "\n",
      "    eFEX_RhE  eFEX_RhH  eFEX_WsN  eFEX_WsD  label  \n",
      "0  20.900000       0.0     0.000     6.700      0  \n",
      "1  29.875000       0.0     0.000     7.200      0  \n",
      "2  18.299999       0.0     0.800     8.850      0  \n",
      "3   7.000000       0.0     1.350     1.350      0  \n",
      "4  35.450001       0.0     0.775    12.325      0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "txt_df =[]\n",
    "txt_File = uproot.open(r\"C:\\Users\\oscar\\OneDrive\\Documents\\Year4_Project\\l1calo_hist_EGZ_extended.root\")\n",
    "txt_Tree = txt_File[\"tree_DMC\"]\n",
    "txt_df.append(txt_File[\"tree_DMC\"].arrays(library=\"pd\"))\n",
    "txt_DF=pd.concat(txt_df)\n",
    "txt_DF.head()\n",
    "Super_ZMUMU = txt_DF['SuperCell_ET'][0:100]\n",
    "# Create a new DataFrame with features and add a 'label' column\n",
    "# Here, we assign label '1' to all the samples from this file\n",
    "Super_ZMUMU_df = pd.DataFrame(Super_ZMUMU)\n",
    "txt_DF['label'] = 0\n",
    "\n",
    "# Now Super_ZMUMU_df has the features and the labels suitable for machine learning training\n",
    "print(txt_DF.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TOB_ET  TOB_eta  TOB_ieta  TOB_ietabin   TOB_phi  offline_ele_pt  \\\n",
      "0  22.500000  -0.2875        -3            2  2.896156       22.860487   \n",
      "1  32.200001  -0.5875        -6            5 -1.619884       30.928337   \n",
      "2  20.000000   0.1375         1            1 -0.638136       20.700048   \n",
      "3   8.900000   1.4875        14           14  1.030835       42.459045   \n",
      "4  38.500000   0.2125         2            2 -1.914408       36.940105   \n",
      "\n",
      "   offline_ele_eta  offline_ele_eta_cal  offline_ele_phi  offline_ele_phi_cal  \\\n",
      "0        -0.278998            -0.286387         2.860483             2.882413   \n",
      "1        -0.596390            -0.588561        -1.626244            -1.639588   \n",
      "2         0.206087             0.150844        -0.584220            -0.609071   \n",
      "3         1.508192             1.500046         0.987355             0.987977   \n",
      "4         0.249134             0.218442        -1.945299            -1.933747   \n",
      "\n",
      "   ...  eFEX_L3_ET                                       SuperCell_ET  \\\n",
      "0  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "1  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "2  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "3  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "4  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "\n",
      "    eFEX_ReC  eFEX_ReE   eFEX_RhE  eFEX_RhH  eFEX_WsN  eFEX_WsD  label  \\\n",
      "0  12.175000       0.0  20.900000       0.0     0.000     6.700      0   \n",
      "1  21.424999       0.0  29.875000       0.0     0.000     7.200      0   \n",
      "2   9.450000       0.0  18.299999       0.0     0.800     8.850      0   \n",
      "3   4.450000       0.0   7.000000       0.0     1.350     1.350      0   \n",
      "4  22.174999       0.0  35.450001       0.0     0.775    12.325      0   \n",
      "\n",
      "                                                L0  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 2.025, 0.0, 0.0, 0.0, 0.0]  \n",
      "1   [0.0, 0.0, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.0]  \n",
      "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "3    [0.0, 0.0, 0.0, 0.0, 1.2, 0.0, 0.0, 0.0, 0.0]  \n",
      "4   [0.0, 0.0, 0.0, 0.0, 0.95, 0.0, 0.0, 0.0, 0.0]  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming txt_DF is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "# Define the function to extract and reorder L0\n",
    "def extract_L0(super_cell_et):\n",
    "    # Convert Awkward Array to a NumPy array\n",
    "    np_array = super_cell_et.to_numpy()  # Using the Awkward Array method to convert to numpy\n",
    "    # Extract L0 by taking every 11th element starting from the 0th index\n",
    "    L0 = np_array[::11]\n",
    "    return L0\n",
    "\n",
    "# Initialize an empty list to store the L0 data\n",
    "L0_data = []\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for i in range(len(txt_DF)):\n",
    "    # Call the extract_L0 function and append the result to L0_data\n",
    "    L0_data.append(extract_L0(txt_DF['SuperCell_ET'].iloc[i]))\n",
    "\n",
    "# Assign the L0_data list as a new column in the DataFrame\n",
    "txt_DF['L0'] = L0_data\n",
    "\n",
    "# Check the new DataFrame with the 'L0' column\n",
    "print(txt_DF.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "\n",
    "# Assuming txt_DF is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "def extract_L1(super_cell_et):\n",
    "    # Make sure the input is an Awkward Array\n",
    "    assert isinstance(super_cell_et, ak.Array), \"Input must be an Awkward Array\"\n",
    "    \n",
    "    # Extract L1 according to the logic provided\n",
    "    L1 = [super_cell_et[i+j] for i in range(0, 99, 11) for j in range(1, 5)]\n",
    "    \n",
    "    return L1\n",
    "\n",
    "# Apply the function to each element of the 'SuperCell_ET' column directly\n",
    "txt_DF['L1'] = [extract_L1(ak_array) for ak_array in txt_DF['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the 'L1' column\n",
    "# print(txt_DF.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  L2\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.125, 0.0...\n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n"
     ]
    }
   ],
   "source": [
    "# Assuming txt_DF is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "def extract_L2(super_cell_et):\n",
    "    # Make sure the input is an Awkward Array\n",
    "    assert isinstance(super_cell_et, ak.Array), \"Input must be an Awkward Array\"\n",
    "    \n",
    "    # Extract L2 according to the logic provided\n",
    "    L2 = [super_cell_et[i+j] for i in range(0, 99, 11) for j in range(5, 9)]\n",
    "    \n",
    "    return L2\n",
    "\n",
    "# Apply the function to each element of the 'SuperCell_ET' column directly\n",
    "txt_DF['L2'] = [extract_L2(ak_array) for ak_array in txt_DF['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the 'L2' column\n",
    "print(txt_DF[['L2']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              L3\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming txt_DF is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "def extract_L3(super_cell_et):\n",
    "    # Make sure the input is an Awkward Array\n",
    "    assert isinstance(super_cell_et, ak.Array), \"Input must be an Awkward Array\"\n",
    "    \n",
    "    # Initialize L3 and the modifier m\n",
    "    L3 = []\n",
    "    m = -1\n",
    "    \n",
    "    # Apply the logic to extract L3\n",
    "    for i in range(1, 99):  # Starting from 1 since we're skipping 0\n",
    "        if i % 10 == 0:\n",
    "            L3.append(super_cell_et[i + m])\n",
    "            m += 1\n",
    "\n",
    "    return L3\n",
    "\n",
    "# Apply the function to each element of the 'SuperCell_ET' column directly\n",
    "txt_DF['L3'] = [extract_L3(ak_array) for ak_array in txt_DF['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the 'L3' column\n",
    "print(txt_DF[['L3']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the extract_Had function to start from the 10th element (index 10)\n",
    "# and jump 11 each time, so it extracts 10, 21, 32, and so on.\n",
    "def extract_Had_adjusted(super_cell_et):\n",
    "    # Initialize Had\n",
    "    Had = []\n",
    "\n",
    "    # Start from the 11th element (index 10) and jump 11 each time\n",
    "    index = 10\n",
    "    while index < len(super_cell_et):\n",
    "        Had.append(super_cell_et[index])\n",
    "        index += 11  # Move to the next index 11 places away\n",
    "    \n",
    "    return Had\n",
    "\n",
    "# Apply the adjusted function to each element of the 'SuperCell_ET' column directly\n",
    "txt_DF['Had'] = [extract_Had_adjusted(np_array) for np_array in txt_DF['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the adjusted 'Had' column\n",
    "#txt_DF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          TOB_ET  TOB_eta  TOB_ieta  TOB_ietabin   TOB_phi  offline_ele_pt  \\\n",
      "0      22.500000  -0.2875        -3            2  2.896156       22.860487   \n",
      "1      32.200001  -0.5875        -6            5 -1.619884       30.928337   \n",
      "2      20.000000   0.1375         1            1 -0.638136       20.700048   \n",
      "3       8.900000   1.4875        14           14  1.030835       42.459045   \n",
      "4      38.500000   0.2125         2            2 -1.914408       36.940105   \n",
      "...          ...      ...       ...          ...       ...             ...   \n",
      "89164  21.799999  -0.5625        -6            5  2.208932       22.560619   \n",
      "89165  26.500000  -0.8125        -9            8 -2.012583       26.853746   \n",
      "89166  28.799999   0.2375         2            2 -2.208932       29.643717   \n",
      "89167  27.500000   0.2875         2            2 -2.994330       28.464281   \n",
      "89168  38.400002   1.4125        14           14  2.110758       35.536255   \n",
      "\n",
      "       offline_ele_eta  offline_ele_eta_cal  offline_ele_phi  \\\n",
      "0            -0.278998            -0.286387         2.860483   \n",
      "1            -0.596390            -0.588561        -1.626244   \n",
      "2             0.206087             0.150844        -0.584220   \n",
      "3             1.508192             1.500046         0.987355   \n",
      "4             0.249134             0.218442        -1.945299   \n",
      "...                ...                  ...              ...   \n",
      "89164        -0.562469            -0.551618         2.231634   \n",
      "89165        -0.816768            -0.808948        -2.036001   \n",
      "89166         0.247778             0.230459        -2.229265   \n",
      "89167         0.266829             0.294036        -2.981246   \n",
      "89168         1.432759             1.439640         2.085009   \n",
      "\n",
      "       offline_ele_phi_cal  ...  eFEX_L1_ET  eFEX_L2_ET  eFEX_L3_ET  \\\n",
      "0                 2.882413  ...       6.700   12.175000        0.00   \n",
      "1                -1.639588  ...       7.200   21.424999        0.00   \n",
      "2                -0.609071  ...       8.850    9.450000        0.00   \n",
      "3                 0.987977  ...       1.350    4.450000        0.00   \n",
      "4                -1.933747  ...      12.325   22.174999        0.00   \n",
      "...                    ...  ...         ...         ...         ...   \n",
      "89164             2.209590  ...       7.675   12.400000        0.00   \n",
      "89165            -2.022409  ...       4.225   17.174999        0.00   \n",
      "89166            -2.245177  ...       8.925   17.174999        0.45   \n",
      "89167            -2.998317  ...       9.725   14.525000        0.00   \n",
      "89168             2.075550  ...       7.500   17.350000        0.00   \n",
      "\n",
      "                                            SuperCell_ET   eFEX_ReC  eFEX_ReE  \\\n",
      "0      [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  12.175000       0.0   \n",
      "1      [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  21.424999       0.0   \n",
      "2      [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   9.450000       0.0   \n",
      "3      [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   4.450000       0.0   \n",
      "4      [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  22.174999       0.0   \n",
      "...                                                  ...        ...       ...   \n",
      "89164  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  12.400000       0.0   \n",
      "89165  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  17.174999       0.0   \n",
      "89166  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  17.174999       0.0   \n",
      "89167  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  14.525000       0.0   \n",
      "89168  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.5 0.0 0.0 1...  17.350000       0.0   \n",
      "\n",
      "        eFEX_RhE  eFEX_RhH  eFEX_WsN  eFEX_WsD  \n",
      "0      20.900000       0.0     0.000     6.700  \n",
      "1      29.875000       0.0     0.000     7.200  \n",
      "2      18.299999       0.0     0.800     8.850  \n",
      "3       7.000000       0.0     1.350     1.350  \n",
      "4      35.450001       0.0     0.775    12.325  \n",
      "...          ...       ...       ...       ...  \n",
      "89164  20.075001       0.0     1.925     7.675  \n",
      "89165  23.350000       0.0     0.000     4.225  \n",
      "89166  26.549999       0.0     0.700     8.925  \n",
      "89167  25.375000       0.0     1.375     9.725  \n",
      "89168  29.650000       0.0     0.250     7.500  \n",
      "\n",
      "[89169 rows x 22 columns]]\n"
     ]
    }
   ],
   "source": [
    "txt_df1 =[]\n",
    "txt_File1 = uproot.open(\"l1calo_hist_EGZ_extended.root\")\n",
    "txt_Tree1 = txt_File1[\"tree_DMC\"]\n",
    "txt_df1.append(txt_File1[\"tree_DMC\"].arrays(library=\"pd\"))\n",
    "txt_DF1=pd.concat(txt_df1)\n",
    "txt_DF1.head()\n",
    "Super_EGZ = txt_DF1['SuperCell_ET']\n",
    "#print(Super_EGZ)\n",
    "Super_EGZ_df = pd.DataFrame(Super_EGZ)\n",
    "\n",
    "txt_DF1['label'] = 1\n",
    "print(txt_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TOB_ET  TOB_eta  TOB_ieta  TOB_ietabin   TOB_phi  offline_ele_pt  \\\n",
      "0  22.500000  -0.2875        -3            2  2.896156       22.860487   \n",
      "1  32.200001  -0.5875        -6            5 -1.619884       30.928337   \n",
      "2  20.000000   0.1375         1            1 -0.638136       20.700048   \n",
      "3   8.900000   1.4875        14           14  1.030835       42.459045   \n",
      "4  38.500000   0.2125         2            2 -1.914408       36.940105   \n",
      "\n",
      "   offline_ele_eta  offline_ele_eta_cal  offline_ele_phi  offline_ele_phi_cal  \\\n",
      "0        -0.278998            -0.286387         2.860483             2.882413   \n",
      "1        -0.596390            -0.588561        -1.626244            -1.639588   \n",
      "2         0.206087             0.150844        -0.584220            -0.609071   \n",
      "3         1.508192             1.500046         0.987355             0.987977   \n",
      "4         0.249134             0.218442        -1.945299            -1.933747   \n",
      "\n",
      "   ...  eFEX_L3_ET                                       SuperCell_ET  \\\n",
      "0  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "1  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "2  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "3  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "4  ...         0.0  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   \n",
      "\n",
      "    eFEX_ReC  eFEX_ReE   eFEX_RhE  eFEX_RhH  eFEX_WsN  eFEX_WsD  label  \\\n",
      "0  12.175000       0.0  20.900000       0.0     0.000     6.700      1   \n",
      "1  21.424999       0.0  29.875000       0.0     0.000     7.200      1   \n",
      "2   9.450000       0.0  18.299999       0.0     0.800     8.850      1   \n",
      "3   4.450000       0.0   7.000000       0.0     1.350     1.350      1   \n",
      "4  22.174999       0.0  35.450001       0.0     0.775    12.325      1   \n",
      "\n",
      "                                                L0  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 2.025, 0.0, 0.0, 0.0, 0.0]  \n",
      "1   [0.0, 0.0, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.0]  \n",
      "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "3    [0.0, 0.0, 0.0, 0.0, 1.2, 0.0, 0.0, 0.0, 0.0]  \n",
      "4   [0.0, 0.0, 0.0, 0.0, 0.95, 0.0, 0.0, 0.0, 0.0]  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming txt_DF1 is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "# Define the function to extract and reorder L0 for the new dataset\n",
    "def extract_L0(super_cell_et):\n",
    "    # Convert Awkward Array to a NumPy array\n",
    "    np_array = super_cell_et.to_numpy()  # Using the Awkward Array method to convert to numpy\n",
    "    # Extract L0_1 by taking every 11th element starting from the 0th index\n",
    "    L0 = np_array[::11]\n",
    "    return L0\n",
    "\n",
    "# Initialize an empty list to store the L0_1 data\n",
    "L0_data = []\n",
    "\n",
    "# Loop through each row in the DataFrame\n",
    "for i in range(len(txt_DF1)):\n",
    "    # Call the extract_L0_1 function and append the result to L0_1_data\n",
    "    L0_data.append(extract_L0(txt_DF1['SuperCell_ET'].iloc[i]))\n",
    "\n",
    "# Assign the L0_1_data list as a new column in the DataFrame\n",
    "txt_DF1['L0'] = L0_data\n",
    "\n",
    "# Check the new DataFrame with the 'L0_1' column\n",
    "print(txt_DF1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TOB_ET  TOB_eta  TOB_ieta  TOB_ietabin   TOB_phi  offline_ele_pt  \\\n",
      "0  22.500000  -0.2875        -3            2  2.896156       22.860487   \n",
      "1  32.200001  -0.5875        -6            5 -1.619884       30.928337   \n",
      "2  20.000000   0.1375         1            1 -0.638136       20.700048   \n",
      "3   8.900000   1.4875        14           14  1.030835       42.459045   \n",
      "4  38.500000   0.2125         2            2 -1.914408       36.940105   \n",
      "\n",
      "   offline_ele_eta  offline_ele_eta_cal  offline_ele_phi  offline_ele_phi_cal  \\\n",
      "0        -0.278998            -0.286387         2.860483             2.882413   \n",
      "1        -0.596390            -0.588561        -1.626244            -1.639588   \n",
      "2         0.206087             0.150844        -0.584220            -0.609071   \n",
      "3         1.508192             1.500046         0.987355             0.987977   \n",
      "4         0.249134             0.218442        -1.945299            -1.933747   \n",
      "\n",
      "   ...                                       SuperCell_ET   eFEX_ReC  \\\n",
      "0  ...  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  12.175000   \n",
      "1  ...  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  21.424999   \n",
      "2  ...  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   9.450000   \n",
      "3  ...  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...   4.450000   \n",
      "4  ...  [0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0...  22.174999   \n",
      "\n",
      "   eFEX_ReE   eFEX_RhE  eFEX_RhH  eFEX_WsN  eFEX_WsD  label  \\\n",
      "0       0.0  20.900000       0.0     0.000     6.700      1   \n",
      "1       0.0  29.875000       0.0     0.000     7.200      1   \n",
      "2       0.0  18.299999       0.0     0.800     8.850      1   \n",
      "3       0.0   7.000000       0.0     1.350     1.350      1   \n",
      "4       0.0  35.450001       0.0     0.775    12.325      1   \n",
      "\n",
      "                                                L0  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 2.025, 0.0, 0.0, 0.0, 0.0]   \n",
      "1   [0.0, 0.0, 0.0, 0.0, 1.25, 0.0, 0.0, 0.0, 0.0]   \n",
      "2    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "3    [0.0, 0.0, 0.0, 0.0, 1.2, 0.0, 0.0, 0.0, 0.0]   \n",
      "4   [0.0, 0.0, 0.0, 0.0, 0.95, 0.0, 0.0, 0.0, 0.0]   \n",
      "\n",
      "                                                  L1  \n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.525...  \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming txt_DF1 is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "def extract_L1(super_cell_et):\n",
    "    # Make sure the input is an Awkward Array\n",
    "    assert isinstance(super_cell_et, ak.Array), \"Input must be an Awkward Array\"\n",
    "    \n",
    "    # Extract L1_1 according to the logic provided\n",
    "    L1 = [super_cell_et[i+j] for i in range(0, 99, 11) for j in range(1, 5)]\n",
    "    \n",
    "    return L1\n",
    "\n",
    "# Apply the function to each element of the 'SuperCell_ET' column directly in txt_DF1\n",
    "txt_DF1['L1'] = [extract_L1(ak_array) for ak_array in txt_DF1['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the 'L1_1' column\n",
    "print(txt_DF1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  L2\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.125, 0.0...\n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "\n",
    "# Assuming txt_DF1 is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "def extract_L2_1(super_cell_et):\n",
    "    # Make sure the input is an Awkward Array\n",
    "    assert isinstance(super_cell_et, ak.Array), \"Input must be an Awkward Array\"\n",
    "    \n",
    "    # Extract L2_1 according to the logic provided\n",
    "    L2_1 = [super_cell_et[i+j] for i in range(0, 99, 11) for j in range(5, 9)]\n",
    "    \n",
    "    return L2_1\n",
    "\n",
    "# Apply the function to each element of the 'SuperCell_ET' column directly in txt_DF1\n",
    "txt_DF1['L2'] = [extract_L2(ak_array) for ak_array in txt_DF1['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the 'L2_1' column\n",
    "print(txt_DF1[['L2']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              L3\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import awkward as ak\n",
    "\n",
    "# Assuming txt_DF1 is your DataFrame and 'SuperCell_ET' is the column with Awkward Arrays\n",
    "\n",
    "def extract_L3_1(super_cell_et):\n",
    "    # Make sure the input is an Awkward Array\n",
    "    assert isinstance(super_cell_et, ak.Array), \"Input must be an Awkward Array\"\n",
    "    \n",
    "    # Initialize L3_1 and the modifier m\n",
    "    L3 = []\n",
    "    m = -1\n",
    "    \n",
    "    # Apply the logic to extract L3_1\n",
    "    for i in range(1, 99):  # Starting from 1 since we're skipping 0\n",
    "        if i % 10 == 0:\n",
    "            L3.append(super_cell_et[i + m])\n",
    "            m += 1\n",
    "\n",
    "    return L3\n",
    "\n",
    "# Apply the function to each element of the 'SuperCell_ET' column directly in txt_DF1\n",
    "txt_DF1['L3'] = [extract_L3(ak_array) for ak_array in txt_DF1['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the 'L3_1' column\n",
    "print(txt_DF1[['L3']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Had\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Adjust the extract_Had function to start from the 10th element (index 10)\n",
    "# and jump 11 each time, so it extracts 10, 21, 32, and so on.\n",
    "def extract_Had_1_adjusted(super_cell_et_1):\n",
    "    # Initialize Had_1\n",
    "    Had = []\n",
    "\n",
    "    # Start from the 11th element (index 10) and jump 11 each time\n",
    "    index = 10\n",
    "    while index < len(super_cell_et_1):\n",
    "        Had_1.append(super_cell_et_1[index])\n",
    "        index += 11  # Move to the next index 11 places away\n",
    "    \n",
    "    return Had\n",
    "\n",
    "# Apply the adjusted function to each element of the 'SuperCell_ET' column directly in txt_DF1\n",
    "txt_DF1['Had'] = [extract_Had_adjusted(ak_array) for ak_array in txt_DF1['SuperCell_ET']]\n",
    "\n",
    "# Check the new DataFrame with the adjusted 'Had_1' column\n",
    "print(txt_DF1[['Had']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#combined_df = pd.concat([txt_DF1, txt_DF[0:26132]], ignore_index=True)\n",
    "\n",
    "# Print combined DataFrame\n",
    "#print(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        L0_1  L0_2  L0_3  L0_4   L0_5  L0_6  L0_7  L0_8  L0_9  L1_1  ...  \\\n",
       "0       0.0  0.00   0.0   0.0  2.025   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1       0.0  0.00   0.0   0.0  1.250   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2       0.0  0.00   0.0   0.0  0.000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3       0.0  0.00   0.0   0.0  1.200   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4       0.0  0.00   0.0   0.0  0.950   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...     ...   ...   ...   ...    ...   ...   ...   ...   ...   ...  ...   \n",
       "89164   0.0  0.00   0.0   0.0  0.000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "89165   0.0  0.00   0.0   0.0  1.950   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "89166   0.0  0.00   0.0   0.0  0.000   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "89167   0.0  0.00   0.0   0.0  1.125   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "89168   0.0  1.05   0.0   0.0  3.750   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "       Had_5  Had_6  Had_7  Had_8  Had_9  label     TOB_ET  offline_ele_pt  \\\n",
       "0        0.0    0.0    0.0    0.0    0.0      0  22.500000       22.860487   \n",
       "1        0.0    0.0    0.0    0.0    0.0      0  32.200001       30.928337   \n",
       "2        0.0    0.0    0.0    0.0    0.0      0  20.000000       20.700048   \n",
       "3        0.0    0.0    0.0    0.0    0.0      0   8.900000       42.459045   \n",
       "4        0.0    0.0    0.0    0.0    0.0      0  38.500000       36.940105   \n",
       "...      ...    ...    ...    ...    ...    ...        ...             ...   \n",
       "89164    0.0    0.0    0.0    0.0    0.0      0  21.799999       22.560619   \n",
       "89165    0.0    0.0    0.0    0.0    0.0      0  26.500000       26.853746   \n",
       "89166    0.0    0.0    0.0    0.0    0.0      0  28.799999       29.643717   \n",
       "89167    0.0    0.0    0.0    0.0    0.0      0  27.500000       28.464281   \n",
       "89168    0.0    0.0    0.0    0.0    0.0      0  38.400002       35.536255   \n",
       "\n",
       "       TOB_eta   TOB_phi  \n",
       "0      -0.2875  2.896156  \n",
       "1      -0.5875 -1.619884  \n",
       "2       0.1375 -0.638136  \n",
       "3       1.4875  1.030835  \n",
       "4       0.2125 -1.914408  \n",
       "...        ...       ...  \n",
       "89164  -0.5625  2.208932  \n",
       "89165  -0.8125 -2.012583  \n",
       "89166   0.2375 -2.208932  \n",
       "89167   0.2875 -2.994330  \n",
       "89168   1.4125  2.110758  \n",
       "\n",
       "[89169 rows x 104 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_extract = ['SuperCell_ET', 'L0', 'L1', 'L2', 'L3', 'Had', 'label','TOB_ET', 'offline_ele_pt', 'TOB_eta','TOB_phi']\n",
    "#columns_to_extract = ['L0']\n",
    "# Select the columns\n",
    "extracted_df = txt_DF[columns_to_extract]\n",
    "#ID = extracted_df['ID']\n",
    "PHI = extracted_df['TOB_phi']\n",
    "Offline_ET = extracted_df['offline_ele_pt']\n",
    "ETA = extracted_df['TOB_eta']\n",
    "TOB_ET = extracted_df['TOB_ET']\n",
    "#extracted_df.head\n",
    "L0_array = extracted_df['L0']\n",
    "list_of_lists = L0_array.tolist()\n",
    "\n",
    "# Create a new DataFrame from the list of lists with proper column names\n",
    "df0 = pd.DataFrame(list_of_lists, columns=['L0_1', 'L0_2', 'L0_3', 'L0_4', 'L0_5', 'L0_6', 'L0_7', 'L0_8', 'L0_9'])\n",
    "L1_array = extracted_df['L1']\n",
    "print(len(L1_array[0]))\n",
    "list_of_lists1 = L1_array.tolist()\n",
    "columns1 = [f'L1_{i}' for i in range(1, 37)]\n",
    "df1 = pd.DataFrame(list_of_lists1, columns= columns1)\n",
    "\n",
    "L2_array = extracted_df['L2']\n",
    "list_of_lists2 = L2_array.tolist()\n",
    "columns2 = [f'L2_{i}' for i in range(1, 37)]\n",
    "df2 = pd.DataFrame(list_of_lists2, columns= columns2)\n",
    "\n",
    "L3_array = extracted_df['L3']\n",
    "list_of_lists3 = L3_array.tolist()\n",
    "columns3 = [f'L3_{i}' for i in range(1, 10)]\n",
    "df3 = pd.DataFrame(list_of_lists3, columns= columns3)\n",
    "\n",
    "Had_array = extracted_df['Had']\n",
    "list_of_lists4 = Had_array.tolist()\n",
    "columns4 = [f'Had_{i}' for i in range(1, 10)]\n",
    "df4 = pd.DataFrame(list_of_lists4, columns= columns4)\n",
    "labels = extracted_df['label']\n",
    "df5 = pd.DataFrame(labels, columns= ['label'])\n",
    "#print(df5)\n",
    "DF0 = df0.join(df1)\n",
    "DF1 = DF0.join(df2)\n",
    "DF2 = DF1.join(df3)\n",
    "DF3 = DF2.join(df4)\n",
    "DF = DF3.join(df5)\n",
    "DF_ET = DF.join(TOB_ET)\n",
    "DF_OFF = DF_ET.join(Offline_ET)\n",
    "DF_ETA = DF_OFF.join(ETA)\n",
    "#DF_ID = DF_ETA.join(ID)\n",
    "DF_PHI = DF_ETA.join(PHI)\n",
    "\n",
    "Super_array =  txt_DF['SuperCell_ET']\n",
    "list_of_listssup = Super_array.tolist()\n",
    "columnssup = [f'{i}' for i in range(1, 100)]\n",
    "df_sup = pd.DataFrame(list_of_listssup, columns= columnssup)\n",
    "DF_sup = df_sup.join(df5)\n",
    "DF_PHI.head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DF_PHI.to_csv('Muon_data_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAGwCAYAAAC0HlECAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkIklEQVR4nO3de1TUdf7H8RdgXFIHU2GQFS+lR2U1SVCcLnZjnTbrHDcrLbZMScvAVMpbF7x0wSzLvKRZ2+ru6sncPVppkR4sLCUvmKUm5pattjZAKUxSAsL8/tgf3+OI1SdEvqM+H+fMOfL9vpl5z/zD83wZxiCfz+cTAAAAflGw3QsAAACcDYgmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYaGL3AueKmpoaHTp0SM2bN1dQUJDd6wAAAAM+n08//PCDYmNjFRz8y9eSiKYGcujQIcXFxdm9BgAAqIeDBw+qbdu2vzhDNDWQ5s2bS/rfi+5wOGzeBgAAmPB6vYqLi7N+jv8SoqmB1P5KzuFwEE0AAJxlTN5awxvBAQAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADDQxO4FEHgSx//N7hUAAGeJgmfvtnuFRsOVJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADNgaTdXV1Xr88cfVsWNHRURE6JJLLtETTzwhn89nzfh8PmVlZalNmzaKiIhQSkqK9u3b53c/hw8fVmpqqhwOh1q0aKG0tDQdPXrUb+azzz7TVVddpfDwcMXFxWnmzJl19lmxYoW6du2q8PBw9ejRQ++8886ZeeIAAOCsY2s0PfPMM1qwYIHmzZunPXv26JlnntHMmTM1d+5ca2bmzJmaM2eOFi5cqM2bN6tp06Zyu906duyYNZOamqrdu3dr3bp1Wr16tTZs2KCRI0da571er/r376/27duroKBAzz77rKZOnapFixZZM5s2bdIdd9yhtLQ0ffLJJxo4cKAGDhyoXbt2Nc6LAQAAAlqQ78TLOo3spptuktPp1F/+8hfr2KBBgxQREaF//OMf8vl8io2N1UMPPaSHH35YklRWVian06nFixdryJAh2rNnj+Lj47V161YlJSVJknJycnTjjTfqm2++UWxsrBYsWKBHH31UHo9HoaGhkqRJkyZp1apVKiwslCQNHjxY5eXlWr16tbVL3759lZCQoIULF/7qc/F6vYqMjFRZWZkcDkeDvUZ2SBz/N7tXAACcJQqevdvuFU7Lb/n5beuVpssvv1y5ubn64osvJEmffvqpPvroI/3xj3+UJO3fv18ej0cpKSnW90RGRio5OVn5+fmSpPz8fLVo0cIKJklKSUlRcHCwNm/ebM3069fPCiZJcrvd2rt3r44cOWLNnPg4tTO1j3OyiooKeb1evxsAADh3NbHzwSdNmiSv16uuXbsqJCRE1dXVeuqpp5SamipJ8ng8kiSn0+n3fU6n0zrn8XgUHR3td75JkyZq2bKl30zHjh3r3EftuYsuukgej+cXH+dk2dnZmjZtWn2eNgAAOAvZeqXpjTfe0NKlS7Vs2TJt375dS5Ys0XPPPaclS5bYuZaRyZMnq6yszLodPHjQ7pUAAMAZZOuVpvHjx2vSpEkaMmSIJKlHjx76z3/+o+zsbA0dOlQxMTGSpKKiIrVp08b6vqKiIiUkJEiSYmJiVFxc7He/x48f1+HDh63vj4mJUVFRkd9M7de/NlN7/mRhYWEKCwurz9MGAABnIVuvNP34448KDvZfISQkRDU1NZKkjh07KiYmRrm5udZ5r9erzZs3y+VySZJcLpdKS0tVUFBgzaxfv141NTVKTk62ZjZs2KCqqiprZt26derSpYsuuugia+bEx6mdqX0cAABwfrM1mm6++WY99dRTWrNmjb7++mutXLlSzz//vP70pz9JkoKCgjR27Fg9+eSTeuutt7Rz507dfffdio2N1cCBAyVJ3bp10w033KARI0Zoy5Yt2rhxozIyMjRkyBDFxsZKku68806FhoYqLS1Nu3fv1vLly/Xiiy8qMzPT2mXMmDHKycnRrFmzVFhYqKlTp2rbtm3KyMho9NcFAAAEHlt/PTd37lw9/vjjeuCBB1RcXKzY2Fjdd999ysrKsmYmTJig8vJyjRw5UqWlpbryyiuVk5Oj8PBwa2bp0qXKyMjQ9ddfr+DgYA0aNEhz5syxzkdGRmrt2rVKT09XYmKiWrduraysLL/Pcrr88su1bNkyPfbYY3rkkUfUuXNnrVq1St27d2+cFwMAAAQ0Wz+n6VzC5zQBAM5HfE4TAAAA/BBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAHbo+m///2v/vznP6tVq1aKiIhQjx49tG3bNuu8z+dTVlaW2rRpo4iICKWkpGjfvn1+93H48GGlpqbK4XCoRYsWSktL09GjR/1mPvvsM1111VUKDw9XXFycZs6cWWeXFStWqGvXrgoPD1ePHj30zjvvnJknDQAAzjq2RtORI0d0xRVX6IILLtC7776rzz//XLNmzdJFF11kzcycOVNz5szRwoULtXnzZjVt2lRut1vHjh2zZlJTU7V7926tW7dOq1ev1oYNGzRy5EjrvNfrVf/+/dW+fXsVFBTo2Wef1dSpU7Vo0SJrZtOmTbrjjjuUlpamTz75RAMHDtTAgQO1a9euxnkxAABAQAvy+Xw+ux580qRJ2rhxoz788MNTnvf5fIqNjdVDDz2khx9+WJJUVlYmp9OpxYsXa8iQIdqzZ4/i4+O1detWJSUlSZJycnJ044036ptvvlFsbKwWLFigRx99VB6PR6GhodZjr1q1SoWFhZKkwYMHq7y8XKtXr7Yev2/fvkpISNDChQt/9bl4vV5FRkaqrKxMDofjtF4XuyWO/5vdKwAAzhIFz95t9wqn5bf8/Lb1StNbb72lpKQk3XbbbYqOjtZll12mV155xTq/f/9+eTwepaSkWMciIyOVnJys/Px8SVJ+fr5atGhhBZMkpaSkKDg4WJs3b7Zm+vXrZwWTJLndbu3du1dHjhyxZk58nNqZ2sc5WUVFhbxer98NAACcu2yNpq+++koLFixQ586d9d5772nUqFF68MEHtWTJEkmSx+ORJDmdTr/vczqd1jmPx6Po6Gi/802aNFHLli39Zk51Hyc+xs/N1J4/WXZ2tiIjI61bXFzcb37+AADg7GFrNNXU1KhXr156+umnddlll2nkyJEaMWKE0a/D7DZ58mSVlZVZt4MHD9q9EgAAOINsjaY2bdooPj7e71i3bt104MABSVJMTIwkqaioyG+mqKjIOhcTE6Pi4mK/88ePH9fhw4f9Zk51Hyc+xs/N1J4/WVhYmBwOh98NAACcu2yNpiuuuEJ79+71O/bFF1+offv2kqSOHTsqJiZGubm51nmv16vNmzfL5XJJklwul0pLS1VQUGDNrF+/XjU1NUpOTrZmNmzYoKqqKmtm3bp16tKli/WXei6Xy+9xamdqHwcAAJzfbI2mcePG6eOPP9bTTz+tf//731q2bJkWLVqk9PR0SVJQUJDGjh2rJ598Um+99ZZ27typu+++W7GxsRo4cKCk/12ZuuGGGzRixAht2bJFGzduVEZGhoYMGaLY2FhJ0p133qnQ0FClpaVp9+7dWr58uV588UVlZmZau4wZM0Y5OTmaNWuWCgsLNXXqVG3btk0ZGRmN/roAAIDA08TOB+/du7dWrlypyZMna/r06erYsaNmz56t1NRUa2bChAkqLy/XyJEjVVpaqiuvvFI5OTkKDw+3ZpYuXaqMjAxdf/31Cg4O1qBBgzRnzhzrfGRkpNauXav09HQlJiaqdevWysrK8vssp8svv1zLli3TY489pkceeUSdO3fWqlWr1L1798Z5MQAAQECz9XOaziV8ThMA4HzE5zQBAADAD9EEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYqFc0XXfddSotLa1z3Ov16rrrrjvdnQAAAAJOvaLpgw8+UGVlZZ3jx44d04cffnjaSwEAAASaJr9l+LPPPrP+/fnnn8vj8VhfV1dXKycnR7/73e8abjsAAIAA8ZuiKSEhQUFBQQoKCjrlr+EiIiI0d+7cBlsOAAAgUPymaNq/f798Pp8uvvhibdmyRVFRUda50NBQRUdHKyQkpMGXBAAAsNtviqb27dtLkmpqas7IMgAAAIHqN0XTifbt26f3339fxcXFdSIqKyvrtBcDAAAIJPWKpldeeUWjRo1S69atFRMTo6CgIOtcUFAQ0QQAAM459YqmJ598Uk899ZQmTpzY0PsAAAAEpHp9TtORI0d02223NfQuAAAAAate0XTbbbdp7dq1Db0LAABAwKrXr+c6deqkxx9/XB9//LF69OihCy64wO/8gw8+2CDLAQAABIp6RdOiRYvUrFkz5eXlKS8vz+9cUFAQ0QQAAM459Yqm/fv3N/QeAAAAAa1e72kCAAA439TrStPw4cN/8fxrr71Wr2UAAAACVb2i6ciRI35fV1VVadeuXSotLT3lf+QLAABwtqtXNK1cubLOsZqaGo0aNUqXXHLJaS8FAAAQaBrsPU3BwcHKzMzUCy+80FB3CQAAEDAa9I3gX375pY4fP96QdwkAABAQ6vXruczMTL+vfT6fvv32W61Zs0ZDhw5tkMUAAAACSb2i6ZNPPvH7Ojg4WFFRUZo1a9av/mUdAADA2ahe0fT+++839B4AAAABrV7RVKukpER79+6VJHXp0kVRUVENshQAAECgqdcbwcvLyzV8+HC1adNG/fr1U79+/RQbG6u0tDT9+OOPDb0jAACA7eoVTZmZmcrLy9Pbb7+t0tJSlZaW6s0331ReXp4eeuihht4RAADAdvX69dy//vUv/fOf/9Q111xjHbvxxhsVERGh22+/XQsWLGio/QAAAAJCva40/fjjj3I6nXWOR0dH8+s5AABwTqpXNLlcLk2ZMkXHjh2zjv3000+aNm2aXC5Xgy0HAAAQKOr167nZs2frhhtuUNu2bdWzZ09J0qeffqqwsDCtXbu2QRcEAAAIBPWKph49emjfvn1aunSpCgsLJUl33HGHUlNTFRER0aALAgAABIJ6RVN2dracTqdGjBjhd/y1115TSUmJJk6c2CDLAQAABIp6vafp5ZdfVteuXesc//3vf6+FCxee9lIAAACBpl7R5PF41KZNmzrHo6Ki9O233572UgAAAIGmXtEUFxenjRs31jm+ceNGxcbGnvZSAAAAgaZe72kaMWKExo4dq6qqKl133XWSpNzcXE2YMIFPBAcAAOekekXT+PHj9f333+uBBx5QZWWlJCk8PFwTJ07U5MmTG3RBAACAQFCvaAoKCtIzzzyjxx9/XHv27FFERIQ6d+6ssLCwht4PAAAgINQrmmo1a9ZMvXv3bqhdAAAAAla93ggOAABwvgmYaJoxY4aCgoI0duxY69ixY8eUnp6uVq1aqVmzZho0aJCKior8vu/AgQMaMGCALrzwQkVHR2v8+PE6fvy438wHH3ygXr16KSwsTJ06ddLixYvrPP78+fPVoUMHhYeHKzk5WVu2bDkTTxMAAJylAiKatm7dqpdfflmXXnqp3/Fx48bp7bff1ooVK5SXl6dDhw7plltusc5XV1drwIABqqys1KZNm7RkyRItXrxYWVlZ1sz+/fs1YMAAXXvttdqxY4fGjh2re++9V++99541s3z5cmVmZmrKlCnavn27evbsKbfbreLi4jP/5AEAwFkhyOfz+exc4OjRo+rVq5deeuklPfnkk0pISNDs2bNVVlamqKgoLVu2TLfeeqskqbCwUN26dVN+fr769u2rd999VzfddJMOHTokp9MpSVq4cKEmTpyokpIShYaGauLEiVqzZo127dplPeaQIUNUWlqqnJwcSVJycrJ69+6tefPmSZJqamoUFxen0aNHa9KkSUbPw+v1KjIyUmVlZXI4HA35EjW6xPF/s3sFAMBZouDZu+1e4bT8lp/ftl9pSk9P14ABA5SSkuJ3vKCgQFVVVX7Hu3btqnbt2ik/P1+SlJ+frx49eljBJElut1ter1e7d++2Zk6+b7fbbd1HZWWlCgoK/GaCg4OVkpJizZxKRUWFvF6v3w0AAJy7Tuuv507X66+/ru3bt2vr1q11znk8HoWGhqpFixZ+x51OpzwejzVzYjDVnq8990szXq9XP/30k44cOaLq6upTzhQWFv7s7tnZ2Zo2bZrZEwUAAGc92640HTx4UGPGjNHSpUsVHh5u1xr1NnnyZJWVlVm3gwcP2r0SAAA4g2yLpoKCAhUXF6tXr15q0qSJmjRpory8PM2ZM0dNmjSR0+lUZWWlSktL/b6vqKhIMTExkqSYmJg6f01X+/WvzTgcDkVERKh169YKCQk55UztfZxKWFiYHA6H3w0AAJy7bIum66+/Xjt37tSOHTusW1JSklJTU61/X3DBBcrNzbW+Z+/evTpw4IBcLpckyeVyaefOnX5/5bZu3To5HA7Fx8dbMyfeR+1M7X2EhoYqMTHRb6ampka5ubnWDAAAgG3vaWrevLm6d+/ud6xp06Zq1aqVdTwtLU2ZmZlq2bKlHA6HRo8eLZfLpb59+0qS+vfvr/j4eN11112aOXOmPB6PHnvsMaWnp1v/pcv999+vefPmacKECRo+fLjWr1+vN954Q2vWrLEeNzMzU0OHDlVSUpL69Omj2bNnq7y8XMOGDWukVwMAAAQ6W98I/mteeOEFBQcHa9CgQaqoqJDb7dZLL71knQ8JCdHq1as1atQouVwuNW3aVEOHDtX06dOtmY4dO2rNmjUaN26cXnzxRbVt21avvvqq3G63NTN48GCVlJQoKytLHo9HCQkJysnJqfPmcAAAcP6y/XOazhV8ThMA4HzE5zQBAADAD9EEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGLA1mrKzs9W7d281b95c0dHRGjhwoPbu3es3c+zYMaWnp6tVq1Zq1qyZBg0apKKiIr+ZAwcOaMCAAbrwwgsVHR2t8ePH6/jx434zH3zwgXr16qWwsDB16tRJixcvrrPP/Pnz1aFDB4WHhys5OVlbtmxp8OcMAADOTrZGU15entLT0/Xxxx9r3bp1qqqqUv/+/VVeXm7NjBs3Tm+//bZWrFihvLw8HTp0SLfccot1vrq6WgMGDFBlZaU2bdqkJUuWaPHixcrKyrJm9u/frwEDBujaa6/Vjh07NHbsWN1777167733rJnly5crMzNTU6ZM0fbt29WzZ0+53W4VFxc3zosBAAACWpDP5/PZvUStkpISRUdHKy8vT/369VNZWZmioqK0bNky3XrrrZKkwsJCdevWTfn5+erbt6/effdd3XTTTTp06JCcTqckaeHChZo4caJKSkoUGhqqiRMnas2aNdq1a5f1WEOGDFFpaalycnIkScnJyerdu7fmzZsnSaqpqVFcXJxGjx6tSZMm/eruXq9XkZGRKisrk8PhaOiXplEljv+b3SsAAM4SBc/ebfcKp+W3/PwOqPc0lZWVSZJatmwpSSooKFBVVZVSUlKsma5du6pdu3bKz8+XJOXn56tHjx5WMEmS2+2W1+vV7t27rZkT76N2pvY+KisrVVBQ4DcTHByslJQUa+ZkFRUV8nq9fjcAAHDuCphoqqmp0dixY3XFFVeoe/fukiSPx6PQ0FC1aNHCb9bpdMrj8VgzJwZT7fnac7804/V69dNPP+m7775TdXX1KWdq7+Nk2dnZioyMtG5xcXH1e+IAAOCsEDDRlJ6erl27dun111+3exUjkydPVllZmXU7ePCg3SsBAIAzqIndC0hSRkaGVq9erQ0bNqht27bW8ZiYGFVWVqq0tNTvalNRUZFiYmKsmZP/yq32r+tOnDn5L+6KiorkcDgUERGhkJAQhYSEnHKm9j5OFhYWprCwsPo9YQAAcNax9UqTz+dTRkaGVq5cqfXr16tjx45+5xMTE3XBBRcoNzfXOrZ3714dOHBALpdLkuRyubRz506/v3Jbt26dHA6H4uPjrZkT76N2pvY+QkNDlZiY6DdTU1Oj3NxcawYAAJzfbL3SlJ6ermXLlunNN99U8+bNrfcPRUZGKiIiQpGRkUpLS1NmZqZatmwph8Oh0aNHy+VyqW/fvpKk/v37Kz4+XnfddZdmzpwpj8ejxx57TOnp6daVoPvvv1/z5s3ThAkTNHz4cK1fv15vvPGG1qxZY+2SmZmpoUOHKikpSX369NHs2bNVXl6uYcOGNf4LAwAAAo6t0bRgwQJJ0jXXXON3/K9//avuueceSdILL7yg4OBgDRo0SBUVFXK73XrppZes2ZCQEK1evVqjRo2Sy+VS06ZNNXToUE2fPt2a6dixo9asWaNx48bpxRdfVNu2bfXqq6/K7XZbM4MHD1ZJSYmysrLk8XiUkJCgnJycOm8OBwAA56eA+pymsxmf0wQAOB/xOU0AAADwQzQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABogkAAMAA0QQAAGCAaAIAADBANAEAABggmgAAAAwQTQAAAAaIJgAAAANEEwAAgAGiCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABoimk8yfP18dOnRQeHi4kpOTtWXLFrtXAgAAAYBoOsHy5cuVmZmpKVOmaPv27erZs6fcbreKi4vtXg0AANiMaDrB888/rxEjRmjYsGGKj4/XwoULdeGFF+q1116zezUAAGCzJnYvECgqKytVUFCgyZMnW8eCg4OVkpKi/Pz8OvMVFRWqqKiwvi4rK5Mkeb3eM7/sGVZd8ZPdKwAAzhJn+8+92v19Pt+vzhJN/++7775TdXW1nE6n33Gn06nCwsI689nZ2Zo2bVqd43FxcWdsRwAAAk3k3PvtXqFB/PDDD4qMjPzFGaKpniZPnqzMzEzr65qaGh0+fFitWrVSUFCQjZsBaGher1dxcXE6ePCgHA6H3esAaEA+n08//PCDYmNjf3WWaPp/rVu3VkhIiIqKivyOFxUVKSYmps58WFiYwsLC/I61aNHiTK4IwGYOh4NoAs5Bv3aFqRZvBP9/oaGhSkxMVG5urnWspqZGubm5crlcNm4GAAACAVeaTpCZmamhQ4cqKSlJffr00ezZs1VeXq5hw4bZvRoAALAZ0XSCwYMHq6SkRFlZWfJ4PEpISFBOTk6dN4cDOL+EhYVpypQpdX4lD+D8EuQz+Rs7AACA8xzvaQIAADBANAEAABggmgAAAAwQTQAAAAaIJgD4FfPnz1eHDh0UHh6u5ORkbdmyxe6VANiAaAKAX7B8+XJlZmZqypQp2r59u3r27Cm3263i4mK7VwPQyPjIAQD4BcnJyerdu7fmzZsn6X//U0BcXJxGjx6tSZMm2bwdgMbElSYA+BmVlZUqKChQSkqKdSw4OFgpKSnKz8+3cTMAdiCaAOBnfPfdd6qurq7zvwI4nU55PB6btgJgF6IJAADAANEEAD+jdevWCgkJUVFRkd/xoqIixcTE2LQVALsQTQDwM0JDQ5WYmKjc3FzrWE1NjXJzc+VyuWzcDIAdmti9AAAEsszMTA0dOlRJSUnq06ePZs+erfLycg0bNszu1QA0MqIJAH7B4MGDVVJSoqysLHk8HiUkJCgnJ6fOm8MBnPv4nCYAAAADvKcJAADAANEEAABggGgCAAAwQDQBAAAYIJoAAAAMEE0AAAAGiCYAAAADRBMAAIABognAeeOaa67R2LFjjWY/+OADBQUFqbS09LQes0OHDpo9e/Zp3QeAwEA0AQAAGCCaAAAADBBNAM5Lf//735WUlKTmzZsrJiZGd955p4qLi+vMbdy4UZdeeqnCw8PVt29f7dq1y+/8Rx99pKuuukoRERGKi4vTgw8+qPLy8sZ6GgAaEdEE4LxUVVWlJ554Qp9++qlWrVqlr7/+Wvfcc0+dufHjx2vWrFnaunWroqKidPPNN6uqqkqS9OWXX+qGG27QoEGD9Nlnn2n58uX66KOPlJGR0cjPBkBjaGL3AgBgh+HDh1v/vvjiizVnzhz17t1bR48eVbNmzaxzU6ZM0R/+8AdJ0pIlS9S2bVutXLlSt99+u7Kzs5Wammq9ubxz586aM2eOrr76ai1YsEDh4eGN+pwAnFlcaQJwXiooKNDNN9+sdu3aqXnz5rr66qslSQcOHPCbc7lc1r9btmypLl26aM+ePZKkTz/9VIsXL1azZs2sm9vtVk1Njfbv3994TwZAo+BKE4DzTnl5udxut9xut5YuXaqoqCgdOHBAbrdblZWVxvdz9OhR3XfffXrwwQfrnGvXrl1DrgwgABBNAM47hYWF+v777zVjxgzFxcVJkrZt23bK2Y8//tgKoCNHjuiLL75Qt27dJEm9evXS559/rk6dOjXO4gBsxa/nAJx32rVrp9DQUM2dO1dfffWV3nrrLT3xxBOnnJ0+fbpyc3O1a9cu3XPPPWrdurUGDhwoSZo4caI2bdqkjIwM7dixQ/v27dObb77JG8GBcxTRBOC8ExUVpcWLF2vFihWKj4/XjBkz9Nxzz51ydsaMGRozZowSExPl8Xj09ttvKzQ0VJJ06aWXKi8vT1988YWuuuoqXXbZZcrKylJsbGxjPh0AjSTI5/P57F4CAAAg0HGlCQAAwADRBAAAYIBoAgAAMEA0AQAAGCCaAAAADBBNAAAABogmAAAAA0QTAACAAaIJAADAANEEAABggGgCAAAw8H/7oApKw9APZAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x =\"label\", data = DF_ETA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'DF_test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save DF to a CSV file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDF_test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save DF_sup to a CSV file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#DF_sup.to_csv('DF1_sup.csv', index=False)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\oscar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'DF_test.csv'"
     ]
    }
   ],
   "source": [
    "# Save DF to a CSV file\n",
    "DF.to_csv('DF_test.csv', index=False)\n",
    "\n",
    "# Save DF_sup to a CSV file\n",
    "#DF_sup.to_csv('DF1_sup.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
